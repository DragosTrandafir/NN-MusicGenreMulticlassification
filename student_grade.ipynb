{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070d6926-9fa1-49fb-9613-09cbd58f924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # used for arrays & loading data\n",
    "import tensorflow as tf # for building neural networks\n",
    "from tensorflow.keras.models import Sequential  # model type that we will use\n",
    "from tensorflow.keras.layers import Dense # we will use Dense layers\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid # some activation functions that we may use\n",
    "from sklearn.preprocessing import StandardScaler # z-score normalization \n",
    "\n",
    "# suppress warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4722ba3f-f993-4031-95e8-b56c2e771795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2392, 15)\n"
     ]
    }
   ],
   "source": [
    "# loading all the training data\n",
    "data = np.loadtxt('Student_performance_data.csv', delimiter=',', skiprows=1 )\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23d4a7f-497d-45e6-866e-81ae897dbb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training input shape:(1435, 14)\n",
      "training output shape:(1435, 1)\n",
      "cv input shape:(478, 14)\n",
      "cv output shape:(478, 1)\n",
      "test input shape:(479, 14)\n",
      "test output shape:(479, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,:-1] # forming the input and output of the training data\n",
    "y = data[:,-1]\n",
    "\n",
    "y = np.expand_dims(y, axis=1) # make y 2D - the commands later will require it\n",
    "\n",
    "\n",
    "# split into training , cross validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TRAINING SET - 60%\n",
    "X_train, X_temporary, y_train, y_temporary = train_test_split(X, y, test_size=0.40, random_state=1)\n",
    "\n",
    "# the rest of 40% - CV SET(20%) and TEST SET(20%)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_temporary, y_temporary, test_size=0.50, random_state=1)\n",
    "del X_temporary, y_temporary\n",
    "\n",
    "print(f\"training input shape:{X_train.shape}\")\n",
    "print(f\"training output shape:{y_train.shape}\")\n",
    "print(f\"cv input shape:{X_cv.shape}\")\n",
    "print(f\"cv output shape:{y_cv.shape}\")\n",
    "print(f\"test input shape:{X_test.shape}\")\n",
    "print(f\"test output shape:{y_test.shape}\")\n",
    "\n",
    "# applying z-score to all the training, cv and test data - adjust the data based on its distribution - Adam will converge faster\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_cv_scaled = standard_scaler.transform(X_cv)\n",
    "X_test_scaled = standard_scaler.transform(X_test)  # use transform, because we want the same z-score used for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5ec5256-3506-4728-ba5c-3b5b75ab2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a Sequential model with Dense layers\n",
    "\n",
    "model= Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(14,)), # input size (each song has 14 features)\n",
    "        Dense(10,activation=\"relu\", name=\"layer1\"),   # usually, for multiclassification we use relu for all layers\n",
    "        Dense(5,activation=\"linear\", name=\"layer2\"), # but for the last layer we use linear \n",
    "    ], name=\"multiclass_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a619a5-2fe4-4319-be85-ca6a2c25f16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"multiclass_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"multiclass_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m150\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ layer2 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m55\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205\u001b[0m (820.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205</span> (820.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205\u001b[0m (820.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see details about the parameters and output of activation at every layer \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672e85c3-6e24-4414-a413-d614aeb7968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer of the Adam's algorithm\n",
    "model.compile(\n",
    "    # this is similar to gradient descent, but it is a much improved version\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # multiclass loss\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01), # preimplemented optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66b76126-c62f-4f63-803a-b203af6c2bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227us/step - loss: 1.5115 \n",
      "Epoch 2/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.8994\n",
      "Epoch 3/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.7712\n",
      "Epoch 4/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.7260\n",
      "Epoch 5/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6854\n",
      "Epoch 6/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.6323\n",
      "Epoch 7/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.6372\n",
      "Epoch 8/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.5986\n",
      "Epoch 9/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.5471\n",
      "Epoch 10/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.5259\n",
      "Epoch 11/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.5458\n",
      "Epoch 12/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.5173\n",
      "Epoch 13/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.5064\n",
      "Epoch 14/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.4935\n",
      "Epoch 15/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.5020\n",
      "Epoch 16/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.4725\n",
      "Epoch 17/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.4517\n",
      "Epoch 18/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.4613\n",
      "Epoch 19/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.4597\n",
      "Epoch 20/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.4422\n",
      "Epoch 21/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.4431\n",
      "Epoch 22/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.4606\n",
      "Epoch 23/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.4320\n",
      "Epoch 24/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.4191\n",
      "Epoch 25/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.4164\n",
      "Epoch 26/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.3839\n",
      "Epoch 27/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.4153\n",
      "Epoch 28/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.4122\n",
      "Epoch 29/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.3926\n",
      "Epoch 30/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.3968\n",
      "Epoch 31/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.3912\n",
      "Epoch 32/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.3692\n",
      "Epoch 33/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.3902\n",
      "Epoch 34/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.4076\n",
      "Epoch 35/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.3354\n",
      "Epoch 36/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.3960\n",
      "Epoch 37/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.3901\n",
      "Epoch 38/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.3523\n",
      "Epoch 39/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.3652\n",
      "Epoch 40/40\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.3633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x215925d0320>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \"epochs\" times\n",
    "model.fit(\n",
    "    X_train_scaled,y_train,\n",
    "    epochs=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372b491e-1716-471b-8139-dd3a44d7ca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step\n",
      "(1435, 5)\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model.predict(X_train_scaled)  # prediction on train dataset (output matrix, where each row has 11 elements - corresponding to the nr of classes)\n",
    "print(y_prediction.shape)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afd44e25-9853-488d-ac70-b0b39cf7d277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "[[3.]\n",
      " [3.]\n",
      " [4.]\n",
      " ...\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "y_prediction_classes=np.empty((1,1))\n",
    "\n",
    "# since we did not use softmax to see the exact probability for every class, argmax will help us to choose the index of the greatest element on each row\n",
    "print(y_prediction_classes.shape)\n",
    "for i in range(y_prediction.shape[0]):\n",
    "    max_element_index = np.argmax(y_prediction[i]) # this index represents the class predicted\n",
    "    y_prediction_classes = np.concatenate((y_prediction_classes,[[max_element_index]]),axis=0)\n",
    "y_prediction_classes = y_prediction_classes[1:]\n",
    "print(y_prediction_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ac74f6c-b00e-4011-8a64-a9947704c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Classification Error: 0.11358885017421602\n"
     ]
    }
   ],
   "source": [
    "error = np.mean(y_prediction_classes != y_train) \n",
    "print(f\"Training Set Classification Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0264925-96a9-4d35-9cf8-28f27e09a9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "(478, 5)\n",
      "CV Set Classification Error: 0.1506276150627615\n"
     ]
    }
   ],
   "source": [
    "# do the exact same operations for CV dataset to see the CV error\n",
    "\n",
    "y_prediction = model.predict(X_cv_scaled) \n",
    "print(y_prediction.shape) \n",
    "\n",
    "y_prediction_classes=np.empty((1,1))\n",
    "for i in range(y_prediction.shape[0]):\n",
    "    max_element_index = np.argmax(y_prediction[i]) # this index represents the class predicted\n",
    "    y_prediction_classes = np.concatenate((y_prediction_classes,[[max_element_index]]),axis=0)\n",
    "y_prediction_classes = y_prediction_classes[1:]\n",
    "\n",
    "error = np.mean(y_prediction_classes != y_cv) \n",
    "print(f\"CV Set Classification Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa36756-cddb-451c-9e9f-298bd1fec25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "(479, 5)\n",
      "Test Set Classification Error: 0.19206680584551147\n"
     ]
    }
   ],
   "source": [
    "# do the exact same operations for TEST dataset to see the TEST error\n",
    "\n",
    "y_prediction = model.predict(X_test_scaled) \n",
    "print(y_prediction.shape) \n",
    "\n",
    "y_prediction_classes=np.empty((1,1))\n",
    "for i in range(y_prediction.shape[0]):\n",
    "    max_element_index = np.argmax(y_prediction[i]) # this index represents the class predicted\n",
    "    y_prediction_classes = np.concatenate((y_prediction_classes,[[max_element_index]]),axis=0)\n",
    "y_prediction_classes = y_prediction_classes[1:]\n",
    "\n",
    "error = np.mean(y_prediction_classes != y_test) \n",
    "print(f\"Test Set Classification Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fca3a014-25e5-4d01-9132-8c8e304c3dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "id : 1001\n",
      "age : 16\n",
      "gender (1/0) : 1\n",
      "etnicity : 0\n",
      "parental_education : 4\n",
      "studytime : 13\n",
      "absences : 2\n",
      "tutoring (1/0) : 1\n",
      "Parental support : 1\n",
      "extracurricular (1/0) : 1\n",
      "sports (1/0): 1\n",
      "music (1/0) : 1\n",
      "volunteering (1/0) : 1\n",
      "gpa : 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Estimated grade is 4.\n"
     ]
    }
   ],
   "source": [
    "# user interaction\n",
    "id = int(input(\"id :\"))\n",
    "age = int(input(\"age :\"))\n",
    "gender = int(input(\"gender (1/0) :\"))\n",
    "etnicity = int(input(\"etnicity :\"))\n",
    "parental_education = int(input(\"parental_education :\"))\n",
    "\n",
    "studytime = int(input(\"studytime :\"))\n",
    "absences = int(input(\"absences :\"))\n",
    "tutoring = int(input(\"tutoring (1/0) :\"))\n",
    "support = int(input(\"Parental support :\"))\n",
    "extra = int(input(\"extracurricular (1/0) :\"))\n",
    "\n",
    "sports = int(input(\"sports (1/0):\"))\n",
    "music = int(input(\"music (1/0) :\"))\n",
    "volunteer = int(input(\"volunteering (1/0) :\"))\n",
    "gpa = int(input(\"gpa :\"))\n",
    "\n",
    "x_user = np.array([[id,age,gender,etnicity,parental_education,studytime,absences,tutoring,support,extra,sports,music,volunteer,gpa]]) # we need a 2D array \n",
    "x_user_scaled = standard_scaler.transform(x_user)\n",
    "y_predicted = model.predict(x_user)\n",
    "max_element_index = np.argmax(y_predicted)\n",
    "\n",
    "print(f\"Estimated grade is {max_element_index}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416442d4-6c32-4239-bb14-cfc21937a5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
